{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOCTwqOuzSOE7Ucmi9ucgvN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# PCA(主成分分析)を用いた異常検知について\n","\n","## 基本アイデア\n","PCAで得られる低次元空間（主成分空間）には、データの主要な分散（情報）が集約される。一方、異常なデータはこの主成分空間にうまく収まらず、主成分に投影した際に大きな誤差（再構成誤差）が生じる。この「再構成誤差」を異常スコアとして利用し、一定の閾値を超える場合を異常値として検出する。\n","\n","## 適用可能データ\n","* 数値データ（特に多次元データ）\n","* 継続的に監視できるセンサーデータ\n","* 時系列データ（ただし前処理が必要な場合あり）\n","* クレジットカード取引データやネットワークログデータのようなパターンを持つデータ\n","\n","## メリット\n","* シンプルで解釈性が高い\n","* 非ラベルデータに対応\n","    * ラベルなしのデータでも適用可能で、異常検知に適している\n","* 次元削減の利点:\n","    * 高次元データを効率的に扱えるため、ノイズや冗長な特徴を削減できる\n","\n","## デメリット\n","* 線形性の前提\n","    * データが**非線形**は関係を持つ場合、再構成誤差がうまく異常を反映しない\n","        * なので、分布が2つ以上あるようなデータ群に対してはPCAは合わない\n","* 閾値の決定\n","    * 再構成誤差の閾値を適切に設定するには、ドメイン知識や経験が必要\n","* 計算コスト\n","    * 高次元かつ大量データでは、PCAの計算コストが増大\n","* 動的なデータへの対応\n","    * 時間とともに変化するデータセットでは、PCAモデルの再訓練が必要\n","\n","\n"],"metadata":{"id":"5o9p16a6jk54"}},{"cell_type":"markdown","source":["## 計算手順\n","### 1. データの前処理\n","* **データのスケーリング**: StandardScaler(平均0、分散1)にデータを標準化\n","* **欠損値の処理**: 補完または除外\n","\n","### 2. PCAによる次元削減\n","1. データ行列$X$を用意\n","2. 共分散行列を計算する\n","$$\n","\\Sigma = \\frac{1}{n} X^T X\n","$$\n","\n","3. 共分散行列の固有値と固有ベクトルを計算し、固有値が大きい順に主成分を選択する。\n","\n","### 3. データの再構成\n","* 元のデータを主成分空間に射影する。\n","$$\n","X_{\\text{projected}} = X W\n","$$\n","    * $W$は主成分ベクトルの行列\n","* 射影されたデータを元の空間に戻す。\n","$$\n","X_{\\text{reconstructed}} = X_{\\text{projected}} W^T\n","$$\n","\n","### 4. 再構成誤差の計算\n","再構成誤差は、元のデータと再構成データの差で定義される。\n","$$\n","\\text{Reconstruction Error} = \\| X - X_{\\text{reconstructed}} \\|^2\n","$$\n","\n","### 5. 閾値による異常検知\n","* 再構成誤差が大きいデータを異常値とみなす\n","* 閾値の設定方法:\n","    * 統計的手法（例えば、再構成誤差が平均±3σを超える場合など）\n","    * ROC曲線を用いた最適閾値の探索\n","    \n"],"metadata":{"id":"VFU2toCQoy1o"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"U_PS-EnqjVK1"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["## PCAにおける「線形性の前提」について\n","PCA(主成分分析)では、基本的にデータが**線形関係を持つ**ことが前提になっている\n","\n","### 主成分分析における線形性の前提\n","#### PCAの数学的背景\n","1. **次元削減の仕組み**:\n","    * PCAは、データの分散が最大となる方向（主成分）を探索する。\n","    * 主成分は、元の特徴空間における線型結合（加重和）として表現される。\n","$$\n","z_i = w_1 x_1 + w_2 x_2 + \\dots + w_n x_n\n","$$\n","    * $z_i$は主成分、$x_1, x_2, \\dots, x_n$は元の特徴、$w_i$は重み\n","\n","2. **線形性の仮定**:\n","    * PCAは、データの分散を説明するために直線的な射影を使用する。このため、元の特徴間に線形関係が強い場合に最も効果を発揮する。\n","    * 非線形な関係（例えば円や曲線など）は、PCAでは効果的に捉えることができない。\n","\n","#### 線形性が前提となる理由\n","* PCAの計算プロセス（共分散行列の分解）線形代数に基づいており、非線形なパターンや特徴をモデル化する仕組みがない。\n","* 主成分は直線的な方向として定義されるため、複雑な曲線的関係を捉えるには不十分。\n","\n","---\n","\n","### 非線形データに対するPCAの限界\n","\n","#### 例：非線形データの問題\n","* **円形の分布**:\n","    * 元のデータが円形（例えば2次元で$x^2 + y^2 = 1$）の場合、PCAはその構造を捉えられない。\n","    * PCAでは、この円形分布を2つの直線方向に分解するが、これは非線形な構造の本質的な特徴を反映していない。\n","\n","#### 再構成誤差の問題\n","非線形データの場合、PCAによる再構成誤差は大きくなりがちで、異常検知の精度が低下する可能性がある。例えば、非線形データの異常をPCAで検出しようとしても、異常が主成分空間内に収まる場合、検出が困難になる。\n","\n","---\n","\n","### 非線形を扱う方法\n","PCAの線形性の限界を克服するために、非線形構造を捉える以下の拡張手法がある\n","\n","1. **カーネルPCA（Kernel PCA）**\n","    * カーネルPCAは、データを高次元の特徴空間に非線形マッピングし、その空間でPCAを適用する。\n","    * カーネル関数（例：ガウシアンカーネル、ポリノミアルカーネル）を使用して非線形関係をモデル化する。\n","    * 適用例:\n","        * 円形や曲線的なデータの異常検知\n","\n","2. **t-SNE (t-Distributed stochastic Neighbor Embedding)**\n","    * t-SNEは非線形次元削減手法で、データの局所的な構造を保持しながら低次元空間にマッピングする\n","    * 主にデータの可視化に使われるが、異常検知にも応用可能。\n","\n","3. **オートエンコーダー**:\n","    * オートエンコーダーはニューラルネットワークを用いた次元削減手法で、非線形な関係をモデル化できる。\n","    * 再構成誤差を異常スコアとして利用する点ではPCAと似ているが、非線形関係にも対応可能。\n","\n","4. **ISOMAP**:\n","    * グラフベースの次元削減手法で、データの非線形構造（多様体）を保持する。\n","    * 例えば、曲がりくねった表面上のデータ分布を効率的に表現可能。\n","\n","---\n","\n","### 線形PCAが適切なケース\n","\n","* 特徴間に線形関係が強い場合\n","* データの次元が比較的低い場合（数十次元以下）\n","* 再構成誤差を用いた異常検知が主な目的の場合\n","\n","### 非線形次元削減が必要なケース\n","* データに非線形なパターン（曲線的な構造や複雑な分布）が含まれる場合\n","* 高次元かつ複雑なデータを扱う場合\n","* 線形PCAで十分な再構成精度が得られない場合\n","\n"],"metadata":{"id":"SC9zOHw2qpv9"}},{"cell_type":"code","source":[],"metadata":{"id":"t07lEyc6vYa9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 複数の分布を持つデータへのPCA適用の問題点\n","\n","### 1. 分布全体を1つの空間に投影する性質\n","* PCAはデータ全体の分散を考慮し、主成分を計算する。このため、複数の異なる分布を持つデータ群では、それぞれの分布が持つ固有の特徴を捉えにくい場合がある。\n","* 例えば以下の場合:\n","    * クラスごとに異なる方向性も持つデータ\n","    * 異なる分布をまたがる異常（境界にある点や全体に分散する異常点）。\n","\n"," ### 2. 主成分のバイアス\n"," * 主成分は全データにおける「最大分散の方向」を基に選択される。このため、大きな分布を持つクラスタにバイアスがかかり、小さいな分布やまれな分布が無視される可能性がある。\n","\n"," ### 3. 再構成誤差が異なる分布で同等に機能しない\n","    * 各分布に異なる特徴（スケールや形状）がある場合、再構成誤差がある分布では異常と見做されるが、別の分布では正常と見做される可能性がある。\n","\n","## PCAが適切に機能する条件\n","1. **各分布が線形である場合**\n","    * 各分布が互いに近い線形関係を持つか、十分に分離されていれば、PCAは適切に機能することがある。\n","2. **分布間の分離が明確である場合**\n","    * 分布間が十分に離れている場合、PCAによる次元削減でそれぞれの分布の主成分がうまく抽出される場合がある。\n","3. **データの変換・前処理が適切に行われている場合**\n","    * 分布間の違いを抑えるため、データのスケーリングやクラスタごとの処理が有効。\n","\n","\n","## 改善手法と代替手法\n","1. **クラスタリングと組み合わせる**\n","    * データに複数の分布がある場合、クラスタリングを事前に行い、各クラスタに対して個別にPCAを適用することで、分布ごとの特徴を考慮した異常検知が可能になる。\n","    * 例：K-meansクラスタリングを使用してクラスタに分け、その後、各クラスタで再構成誤差を計算。\n","2. **カーネルPCAの活用**\n","    * 非線形分布や複数の分布をより効果的に扱うために、カーネルPCAを用いることができる。カーネルPCAでは、非線形な特徴を考慮しつつデータを射影できるため、複数分布の特性を保持できる。\n","3. **ガウス混合モデル (GMM)**\n","    * 分布が複数存在する場合、ガウス混合モデルを用いることで、データを複数の正規分布の線形結合としてモデリングできる。異常検知には、各データ点の混合分布への尤度（ログ尤度）を利用する。\n","4. **ロバストPCA (Robust PCA)**\n","    * ノイズや異常値に強い次元削減手法であるロバストPCAを使用することで、複数分布の影響を低減しつつ異常検知を行える。\n","5. **クラスタごとの再構成誤差の調整**\n","    * CAを適用した後、クラスタごとに再構成誤差を標準化して異常スコアを計算する方法。このアプローチにより、クラスタ間の再構成誤差の違いを補正できる。\n","6. **ディープラーニングを用いたアプローチ**\n","    * オートエンコーダを使用すると、複雑な分布間の非線形関係を学習でき、PCAよりも柔軟な異常検知が可能。\n"],"metadata":{"id":"o5cCpV89wQzq"}},{"cell_type":"code","source":[],"metadata":{"id":"FY5kOmGI43Dk"},"execution_count":null,"outputs":[]}]}